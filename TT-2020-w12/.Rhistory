install.packages("schrute")
library(schrute)
#https://bradlindblad.github.io/schrute/articles/theoffice.html
mydata <- schrute::theoffice
library(tidyverse)
library(ggplot2)
library(ggtext)
library(tidytext)
library(ggpmthemes)
library(patchwork)
library(here)
mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:3) %>%
knitr::kable()
mydata_glimpse <-mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:3) %>%
knitr::kable()
mydata_glimpse <-mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:3)
View(mydata_glimpse)
mydata_glimpse <-mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:10)
mydata_glimpse <-mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:10) %>%
knitr::kable()
ydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:10) %>%
knitr::kable()
mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:10) %>%
knitr::kable()
mydata %>%
dplyr::filter(season == '01') %>%
dplyr::filter(episode == '01') %>%
dplyr::slice(1:20) %>%
knitr::kable()
#https://bradlindblad.github.io/schrute/articles/theoffice.html
theoffice_data <- schrute::theoffice
get_sentiments("nrc")
library(schrute)
library(tidyverse)
library(ggplot2)
library(ggtext)
library(tidytext)
library(ggpmthemes)
library(patchwork)
library(here)
get_sentiments("nrc")
install.packages("textdata")
library(textdata)
get_sentiments("nrc")
get_sentiments('nrc_vad')
lexicon_nrc_vad()
#tokenize all the lines
token_theoffice_data <- theoffice_data %>%
tidytext::unnest_tokens(word, text)
dominance_lexicon<-lexicon_nrc_vad()
# Looking at trust at the office
#lexicon for sentiment analysis
# Name: NRC Word-Emotion Association Lexicon
# URL: http://saifmohammad.com/WebPages/lexicons.html
trust_sentimenta<-get_sentiments("nrc")
View(trust_sentimenta)
#dominance_lexicon<-lexicon_nrc_vad()
nrc_trust <- trust_sentiments %>%
filter(sentiment == "trust")
# Looking at trust at the office
#lexicon for sentiment analysis
# Name: NRC Word-Emotion Association Lexicon
# URL: http://saifmohammad.com/WebPages/lexicons.html
trust_sentiments<-get_sentiments("nrc")
#dominance_lexicon<-lexicon_nrc_vad()
nrc_trust <- trust_sentiments %>%
filter(sentiment == "trust")
token_theoffice_data %>%
inner_join(nrc_trust) %>%
count(word, sort = TRUE)
View(token_theoffice_data)
#tokenize all the lines
token_theoffice_data <- theoffice_data %>%
tidytext::unnest_tokens(word, text)%>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word))
# Looking at trust at the office
#lexicon for sentiment analysis
# Name: NRC Word-Emotion Association Lexicon
# URL: http://saifmohammad.com/WebPages/lexicons.html
trust_sentiments<-get_sentiments("nrc")
#dominance_lexicon<-lexicon_nrc_vad()
nrc_trust <- trust_sentiments %>%
filter(sentiment == "trust")
#tokenize all the lines and remove stop words
token_theoffice_data <- theoffice_data %>%
tidytext::unnest_tokens(word, text)%>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word))%>%
inner_join(nrc_trust)
#tokenize all the lines and remove stop words
token_theoffice_data <- theoffice_data %>%
tidytext::unnest_tokens(word, text)%>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word))%>%
inner_join(nrc_trust, by = "word")
token_theoffice_data %>%
group_by(character) %>%
summarize(total= n()) %>%
ungroup()
dfff<-token_theoffice_data %>%
group_by(character) %>%
summarize(total= n()) %>%
ungroup()
View(dfff)
#tokenize all the lines and remove stop words
token_theoffice_data <- theoffice_data %>%
tidytext::unnest_tokens(word, text)%>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word))%>%
inner_join(nrc_trust, by = "word")%>%
filter(sentiment == "trust")
dfff<-token_theoffice_data %>%
group_by(character) %>%
summarize(total= n()) %>%
ungroup()
token_theoffice_data %>%
group_by(character) %>%
summarize(total= n())
# Looking at trust at the office
#lexicon for sentiment analysis
# Name: NRC Word-Emotion Association Lexicon
# URL: http://saifmohammad.com/WebPages/lexicons.html
trust_sentiments<-get_sentiments("nrc")
library(schrute)
library(tidyverse)
library(ggplot2)
library(ggtext)
library(tidytext)
library(textdata)
library(ggpmthemes)
library(patchwork)
library(here)
#https://bradlindblad.github.io/schrute/articles/theoffice.html
theoffice_data <- schrute::theoffice
# Looking at trust at the office
#lexicon for sentiment analysis
# Name: NRC Word-Emotion Association Lexicon
# URL: http://saifmohammad.com/WebPages/lexicons.html
emortion_sentiments<-get_sentiments("nrc")
#tokenize all the lines and remove stop words
token_theoffice_data <- theoffice_data %>%
tidytext::unnest_tokens(word, text)%>%
anti_join(stop_words, by = "word") %>%
filter(!grepl('[0-9]', word))%>%
inner_join(emortion_sentiments, by = "word")
total_words_count <- token_theoffice_data %>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= n(token_theoffice_data[sentiment == "trust"]))
total_words_count <- token_theoffice_data %>%
mutate(trust_ind = if(sentiment == "trust"]) 1 else 0)%>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(trust_ind)
# total count of words used
total_words_count <- token_theoffice_data %>%
total_words_count <- token_theoffice_data %>%
mutate(trust_ind = if(sentiment == "trust") 1 else 0)%>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(trust_ind)
)
total_words_count <- token_theoffice_data %>%
mutate(trust_ind = if(sentiment == "trust") 1 else 0)%>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(trust_ind))
# total count of words used
total_words_count <- token_theoffice_data %>%
mutate(trust_ind = if(sentiment == "trust") 1 else 0)%>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
ungroup()
# total count of words used
total_words_count <- token_theoffice_data %>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
ungroup()
View(total_words_count)
# total count of words used and truth_words
total_words_count <- token_theoffice_data %>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
arrange(desc(total_sum))%>%
ungroup()
# total count of words used and truth_words
total_words_count <- token_theoffice_data %>%
group_by(character) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
arrange(desc(total_sum))%>%
mutate(percent_trust_words = total_trust/total_sum)%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
arrange(desc(total_sum))%>%
mutate(percent_trust_words = total_trust/total_sum)%>%
ungroup()
View(michael_words_count)
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
arrange(desc(total_sum))%>%
mutate(percent_trust_words = total_trust/total_sum)%>%
arrange(desc(season))%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season) %>%
summarize(total_sum= n(),
total_trust= sum(sentiment == "trust")) %>%
arrange(desc(total_sum))%>%
mutate(percent_trust_words = total_trust/total_sum)%>%
arrange(season)%>%
ungroup()
token_theoffice_data %>%
inner_join(get_sentiments("nrc")) %>%
group_by(episode, season, sentiment) %>%
summarize(n = n()) %>%
ggplot(aes(x = episode, y = n, fill = season)) +
geom_bar(stat = "identity", alpha = 0.8) +
facet_wrap(~ sentiment, ncol = 5)
token_theoffice_data %>%
group_by(episode, season, sentiment) %>%
summarize(n = n()) %>%
ggplot(aes(x = episode, y = n, fill = season)) +
geom_bar(stat = "identity", alpha = 0.8) +
facet_wrap(~ sentiment, ncol = 5)
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season, episode)%>%
summarize(total_sum= n())%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season, episode, sentiment) %>%
summarize(total_sentiment= n()) %>%
mutate(total_trust = total_sentiment / sum(total_sentiment),
ercent_trust_words = total_trust/total_sum)%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season, episode, sentiment) %>%
summarize(total_sentiment= n()) %>%
mutate(total_trust = total_sentiment / sum(total_sentiment),
ercent_trust_words = total_trust/total_sentiment)%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season, episode, sentiment) %>%
summarize(total_each_sentiment= n()) %>%
mutate(total_sentiment = sum(total_each_sentiment),
ercent_trust_words = total_each_sentiment/total_sentiment)%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(season, episode, sentiment) %>%
summarize(total_each_sentiment= n()) %>%
mutate(total_sentiment = sum(total_each_sentiment),
percent_trust_words = total_each_sentiment/total_sentiment)%>%
ungroup()
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(character,season, episode, sentiment) %>%
summarize(total_each_sentiment= n()) %>%
mutate(total_sentiment = sum(total_each_sentiment),
percent_trust_words = total_each_sentiment/total_sentiment)%>%
ungroup()
install.packages("waffle")
library(waffle)
#look at Michael Scott
michael_words_count <- token_theoffice_data %>%
filter(character == 'Michael') %>%
group_by(character,season, sentiment) %>%
summarize(total_each_sentiment= n()) %>%
mutate(total_sentiment = sum(total_each_sentiment),
percent_trust_words = total_each_sentiment/total_sentiment)%>%
ungroup()
p_waldorf <- ggplot(michael_words_count,
aes(values = total_each_sentiment,
fill = sentiment)) +
geom_waffle(color = "#F8F8FF", size = .25, n_rows = 10, flip = TRUE) +
facet_wrap(~ season, nrow = 4, strip.position = "bottom") +
coord_equal() +
guides(fill = FALSE)
library(waffle)
p_waldorf <- ggplot(michael_words_count,
aes(values = total_each_sentiment,
fill = sentiment)) +
waffle::geom_waffle(color = "#F8F8FF", size = .25, n_rows = 10, flip = TRUE) +
facet_wrap(~ season, nrow = 4, strip.position = "bottom") +
coord_equal() +
guides(fill = FALSE)
library(schrute)
library(tidyverse)
library(ggplot2)
library(ggtext)
library(tidytext)
library(textdata)
library(ggpmthemes)
library(patchwork)
library(here)
library(waffle)
p_waldorf <- ggplot(michael_words_count,
aes(values = total_each_sentiment,
fill = sentiment)) +
geom_waffle(color = "#F8F8FF", size = .25, n_rows = 10, flip = TRUE) +
facet_wrap(~ season, nrow = 4, strip.position = "bottom") +
coord_equal() +
guides(fill = FALSE)
remotes::install_github("hrbrmstr/waffle")
library(waffle) #emotes::install_github("hrbrmstr/waffle")
p_waldorf <- ggplot(michael_words_count,
aes(values = total_each_sentiment,
fill = sentiment)) +
geom_waffle(color = "#F8F8FF", size = .25, n_rows = 10, flip = TRUE) +
facet_wrap(~ season, nrow = 4, strip.position = "bottom") +
coord_equal() +
guides(fill = FALSE)
p_waldorf <- ggplot(michael_words_count,
aes(values = total_each_sentiment,
fill = sentiment)) +
waffle(color = "#F8F8FF", size = .25, n_rows = 10, flip = TRUE) +
facet_wrap(~ season, nrow = 4, strip.position = "bottom") +
coord_equal() +
guides(fill = FALSE)
p_waldorf <- ggplot(michael_words_count,
aes(values = total_each_sentiment,
fill = sentiment)) +
geom_pictogram(color = "#F8F8FF", size = .25, n_rows = 10, flip = TRUE) +
facet_wrap(~ season, nrow = 4, strip.position = "bottom") +
coord_equal() +
guides(fill = FALSE)
install.packages("ggplot2")
install.packages("tidyverse")
library(schrute)
library(tidyverse)
library(ggplot2)
library(ggtext)
library(tidytext)
library(textdata)
library(ggpmthemes)
library(patchwork)
library(here)
library(waffle)
install.packages("waffle", repos = "https://cinc.rud.is")
